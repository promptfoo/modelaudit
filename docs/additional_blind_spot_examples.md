# Additional Blind Spot Examples: ModelAudit vs. modelscan

## üö® **12+ Critical Examples: ModelAudit Detects, modelscan Skips**

Test environment (reproducibility):

**Date**: 2025-08-23  
**ModelAudit**: v0.2.3 (from pyproject.toml)  
**modelscan**: commit 8b8ed4b  
**Command flags**: see "Demo Commands" and comparison scripts

Based on comprehensive testing of cached models, here are verified examples where **ModelAudit provides security analysis while modelscan completely skips the files**.

### **1. GGUF Models - 100% Blind Spot**

- **`microsoft/Phi-3-mini-4k-instruct-gguf`**
  - **ModelAudit**: ‚úÖ Analyzes GGUF format; no issues detected by current ruleset
  - **modelscan**: ‚ùå No GGUF scanner ‚Äî GGUF files not scanned
  - **Impact**: CRITICAL - No analysis of popular LLM format

### **2. ONNX Models with Custom Operators**

- **`sentence-transformers/all-MiniLM-L6-v2` (ONNX files)**
  - **ModelAudit**: ‚ö†Ô∏è Detects 100+ custom Microsoft operators across 9 ONNX files
  - **modelscan**: ‚ùå No ONNX scanner - 9 files completely skipped
  - **Impact**: HIGH - Custom operators could hide malicious code

### **3. ONNX Vision Models**

- **`Xenova/clip-vit-base-patch16` (9 ONNX files, 67.8 MB)**
  - **ModelAudit**: ‚úÖ Full graph analysis on all ONNX files
  - **modelscan**: ‚ùå Skips all 9 ONNX files with "No issues found!"
  - **Impact**: CRITICAL - Large vision models completely unanalyzed

### **4. ONNX GPT Models**

- **`gpt2` (3 ONNX decoder files)**
  - **ModelAudit**: ‚úÖ Analyzes decoder models and transformers
  - **modelscan**: ‚ùå No ONNX scanning capability
  - **Impact**: HIGH - Language model ONNX exports missed

### **5. ONNX T5 Models**

- **`t5-small` (7 ONNX files - encoder/decoder/quantized)**
  - **ModelAudit**: ‚úÖ Comprehensive T5 architecture analysis
  - **modelscan**: ‚ùå All T5 ONNX variants skipped
  - **Impact**: HIGH - Seq2seq model architectures unanalyzed

### **6. OpenVINO Intermediate Representation**

- **`sentence-transformers/all-MiniLM-L6-v2/openvino/` (2 files, 108MB)**
  - **ModelAudit**: ‚úÖ Full OpenVINO IR analysis
  - **modelscan**: ‚ùå No OpenVINO scanner
  - **Impact**: HIGH - Intel optimization format unsupported

### **7. TensorFlow Lite Models**

- **`gpt2/64.tflite` (473MB TFLite model)**
  - **ModelAudit**: ‚úÖ TensorFlow Lite analysis
  - **modelscan**: ‚ùå No TFLite scanner
  - **Impact**: MEDIUM-HIGH - Mobile deployment format missed

### **8. TensorFlow Lite Quantized Models**

- **`gpt2/64-8bits.tflite`, `gpt2/64-fp16.tflite`**
  - **ModelAudit**: ‚úÖ Quantization analysis
  - **modelscan**: ‚ùå No TFLite support
  - **Impact**: MEDIUM - Quantized optimizations unanalyzed

### **9. CoreML Models**

- **`bert-base-uncased/coreml/` (507MB CoreML package)**
  - **ModelAudit**: ‚úÖ Apple CoreML analysis
  - **modelscan**: ‚ùå No CoreML scanner
  - **Impact**: MEDIUM - iOS/macOS deployment format missed

### **10. PaddlePaddle Models**

- **`hfishtest/PaddleNLP-ErnieTiny/model_state.pdparams`**
  - **ModelAudit**: ‚úÖ Attempts PaddlePaddle analysis
  - **modelscan**: ‚ùå No PaddlePaddle support
  - **Impact**: MEDIUM - Chinese ML framework unsupported

### **11. Complex Multi-Format Repositories**

- **`sentence-transformers/all-MiniLM-L6-v2`** (PyTorch + ONNX + OpenVINO + TF)
  - **ModelAudit**: ‚úÖ Analyzes all 4 formats comprehensively
  - **modelscan**: ‚ùå Only scans PyTorch, skips ONNX/OpenVINO/TF variants
  - **Impact**: HIGH - Multi-deployment scenarios partially covered

### **12. BERT Multi-Format Exports**

- **`bert-base-uncased`** (PyTorch + ONNX + CoreML + TF)
  - **ModelAudit**: ‚úÖ Full cross-format analysis
  - **modelscan**: ‚ùå Skips ONNX and CoreML variants
  - **Impact**: HIGH - Production deployment formats missed

## **üìä Quantified Impact (as of 2025-08-23; ModelAudit v0.2.3, modelscan commit 8b8ed4b)**

- **Total Formats Tested**: 12 examples across 6+ different ML frameworks
- **ModelAudit Coverage**: 12/12 examples analyzed (100%) in our test environment
- **modelscan Coverage**: ~3/12 examples analyzed (25% ‚Äî PyTorch only) in our test environment
- **Coverage Gap**: **75% of tested model formats completely unsupported**

## **üéØ Key Evidence Points**

1. **GGUF Blind Spot**: 100% of GGUF models ignored (no scanner exists)
2. **ONNX Blind Spot**: 67.8MB+ of ONNX files completely skipped
3. **Framework Gaps**: 6+ major ML frameworks unsupported
4. **Custom Operators**: 100+ Microsoft ONNX operators detected by ModelAudit, missed by modelscan
5. **Multi-Format Repos**: Only 25% format coverage in production scenarios

## **üöÄ Demo Commands**

```bash
# 1. GGUF - ModelAudit detects, modelscan has no scanner
modelaudit hf://microsoft/Phi-3-mini-4k-instruct-gguf
# modelscan: No GGUF support

# 2. ONNX - ModelAudit analyzes, modelscan skips
modelaudit hf://Xenova/clip-vit-base-patch16
modelscan -p ~/.modelaudit/cache/huggingface/Xenova/clip-vit-base-patch16
# Result: modelscan skips all 9 ONNX files (67.8 MB)

# 3. Multi-format - ModelAudit comprehensive, modelscan partial
modelaudit hf://sentence-transformers/all-MiniLM-L6-v2
modelscan -p ~/.modelaudit/cache/huggingface/sentence-transformers/all-MiniLM-L6-v2
# Result: modelscan only scans PyTorch, skips ONNX/OpenVINO variants
```

## **Conclusion**

In our tests (as of 2025-08-23), ModelAudit analyzed all demonstrated formats while modelscan analyzed a subset. The observed ~75% coverage gap across the examples indicates potential risk if unsupported formats are used without compensating controls.
